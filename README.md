# DL&RL_PlayGround

# ğŸ˜„DL&RLæ¸¸ä¹å›­

- The code repo contains multiple code reproduction processes of various SOTA deep learning algorithms.
- è¿™ä¸ªä»£ç ä»“åº“åŒ…å«äº†ç»å…¸ã€çƒ­é—¨ã€ä»¥åŠSOTAçš„DL/RLç®—æ³•çš„å¤ç°ã€‚
- æˆ‘ä¼šåœ¨ä¸šä½™æ—¶é—´ï¼Œå¯¹æ„Ÿå…´è¶£çš„DL/RLç®—æ³•è¿›è¡Œå¤ç°ï¼Œå¹¶ç¬¬ä¸€æ—¶é—´æ›´æ–°ç»´æŠ¤è¯¥Repoã€‚

## å…³é”®ä¾èµ–é¡¹

- transformers
  - `pip install transformers`
- torch  1.10.1
- torchvision                   0.11.2
- torchtext                     0.11.1

## I. Seq2Seq(TO-DO)

## II. Transformer Basic

#### â‘  Step By Stepä¹‹TransformeråŸºç¡€å®ç°

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [Step By Stepä¹‹TransformeråŸºç¡€å®ç°](https://github.com/HzcIrving/DeepLearning_PlayGround/tree/main/TransformerBasic)
- [ğŸš€ï¸Colab](https://github.com/HzcIrving/DeepLearning_PlayGround/blob/main/TransformerBasic/Transformer%E5%9F%BA%E7%A1%80%E5%AE%9E%E7%8E%B0StepByStep.ipynb)
- Encoder
  - Positional Encoding
  - Attention Machanism
  - Trick ---- Padding Mask
  - Add & Norm Layer
- Decoder
  - Masked Self-Attention
  - Masked Encoder-Decoder Attention

## III. VIT

#### â‘  TransformersåŒ…ä¸­çš„VIT-Demo

- è¯¥æ¥å£å¯ä»¥ç›´æ¥è°ƒç”¨é¢„è®­ç»ƒçš„VITæ¨¡å‹å¯¹ç»™å®šå›¾ç‰‡è¿›è¡Œåˆ†ç±»ã€‚
- [VIT.pyè„šæœ¬](https://github.com/HzcIrving/DeepLearning_PlayGround/blob/main/VIT/VITDemo/VIT.py)

#### â‘¡ Step By Stepä¹‹TransformeråŸºç¡€å®ç°

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [Step By Stepä¹‹TransformeråŸºç¡€å®ç°](https://github.com/HzcIrving/DeepLearning_PlayGround/tree/main/VIT/BasicVIT)
- VITæ˜¯Transformeråœ¨CVå›¾ç‰‡åˆ†ç±»ç§çš„ä¸€ç§åº”ç”¨ï¼ŒVITçš„å®éªŒç»“è®ºæ˜¯ï¼Œåœ¨é¢„è®­ç»ƒDatasetè¶³å¤Ÿå¤§çš„å‰æä¸‹ï¼Œæ‰€æœ‰æ•°æ®é›†çš„è¡¨ç°æ˜¯è¶…è¿‡ResNetçš„ã€‚
- VITçš„æœ¬è´¨æ˜¯ä¸€ä¸ªTransformerçš„Encoderç½‘ç»œã€‚
- ğŸš€ï¸ [Colab ](https://colab.research.google.com/drive/1eCH380s0Yrt4DMERH1cQkbDZbK0Dufqt)

#### â‘¢ Pre-trained VIT

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [Pre-trained VIT](https://github.com/HzcIrving/DeepLearning_PlayGround/tree/main/VIT)
- åŸºäº `ViT-B_16`é¢„è®­ç»ƒæ¨¡å‹ + VIT Model

## IV. Swin Transformer

#### â‘  Step By Step ä¹‹ Swin Transformerå®ç°

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—ï¼š[Swin Transformer](https://github.com/HzcIrving/DeepLearning_PlayGround/tree/main/Swin-Transformer)
- Swin Transformer è¢«è§†ä¸ºCNNçš„ç†æƒ³æ›¿ä»£æ–¹æ¡ˆï¼Œå…¶åœ¨è®¾è®¡æ—¶ä¹Ÿèåˆäº†å¾ˆå¤šCNNçš„æ€æƒ³ã€‚
- Swin Transformer ç»“åˆCNNæ€æƒ³ï¼Œå¼•å…¥å±‚æ¬¡åŒ–æ„å»ºæ–¹å¼æ„å»ºå±‚æ¬¡åŒ–çš„Transformerï¼Œä½¿å¾—SwinTå¯ä»¥åšå±‚çº§å¼çš„ç‰¹å¾æå–ï¼ˆæ–¹ä¾¿ä¸‹æ¸¸å¤šå°ºåº¦çš„æ£€æµ‹ã€åˆ†å‰²ä»»åŠ¡ï¼‰ã€‚è¯æ˜äº†Swin Transformerå¯ä»¥ä½œä¸ºé€šç”¨çš„è§†è§‰ä»»åŠ¡Backboneç½‘ç»œã€‚
- è¯¦æƒ…ï¼š[çŸ¥ä¹: DLPlayGroundä¹‹Swin-Transformer(v1)](https://zhuanlan.zhihu.com/p/467158838)

## V. Meta Learning Part(TO-DO)

## VI. Offline RL

#### â‘  Offline RL Introduction

- åŸºç¡€çŸ¥è¯†ç‚¹ç¬”è®°è·³è½¬é“¾æ¥ğŸ”—: [Offline RL -- Introduction](https://github.com/HzcIrving/DeepLearning_PlayGround/blob/main/Offline%20RL/Introduction/OFFLINE_RL.pdf)

#### â‘¡ Decision Transformer

DTå°†RLçœ‹æˆä¸€ä¸ªåºåˆ—å»ºæ¨¡é—®é¢˜ï¼ˆSequence Modeling Problem ï¼‰ï¼Œä¸ç”¨ä¼ ç»ŸRLæ–¹æ³•ï¼Œè€Œä½¿ç”¨ç½‘ç»œç›´æ¥è¾“å‡ºåŠ¨ä½œè¿›è¡Œå†³ç­–ã€‚

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [DecisionTransformer_StepbyStep](https://github.com/HzcIrving/DecisionTransformer_StepbyStep)

#### â‘¢ BCQ

Batch-Constrained deep Q- Learning(BCQ)

* ä¼˜åŒ–Valueå‡½æ•°æ—¶å€™åŠ å…¥future uncertaintyçš„è¡¡é‡ï¼›
* åŠ å…¥äº†è·ç¦»é™åˆ¶ï¼Œé€šè¿‡state-conditioned generative modelå®Œæˆï¼›
* Qç½‘ç»œé€‰æ‹©æœ€é«˜ä»·å€¼çš„åŠ¨ä½œï¼›
* åœ¨ä»·å€¼æ›´æ–°æ—¶å€™ï¼Œåˆ©ç”¨Double Qçš„ä¼°è®¡å–soft minimum; $r+\gamma max_{a_i}[\lambda min_{j=1,2}Q_{\theta' *j}(s',a_i)+(1-\lambda)max* {j=1,2}Q_{\theta'_j}(s',a_i)$ æ˜¯Convex Combination è€Œä¸æ˜¯ Hard Minimum ...

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [BCQ](https://github.com/HzcIrving/DLRL-PlayGround/tree/main/Offline%20RL/BCQ)

#### â‘£ AWAC 

å…³é”®ç‚¹ï¼š

- Trains well offline
- Fine-tunes quickly online
- Does not need to estimate a behavior model.
- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: AWAC

## Distributional RL

#### â‘  C51

- é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [C51](https://github.com/HzcIrving/DLRL-PlayGround/tree/main/Distributional%20RL/C51)

#### â‘¡ D4PG

Distributed Distributional Determinisitic Policy Gradient (D4PG)

D4PGå°†ç»éªŒæ”¶é›†çš„Actorå’Œç­–ç•¥å­¦ä¹ çš„Learneråˆ†å¼€ï¼š

* ä½¿ç”¨å¤šä¸ªå¹¶è¡Œçš„Actorè¿›è¡Œæ•°æ®æ”¶é›†ï¼Œå³åˆ†å¸ƒå¼çš„é‡‡æ ·ï¼›
* åˆ†äº«ä¸€ä¸ªå¤§çš„ç»éªŒæ•°æ®ç¼“å­˜åŒºï¼Œå‘é€ç»™Learnerè¿›è¡Œå­¦ä¹ ï¼ŒLearnerä»Bufferä¸­é‡‡æ ·ï¼Œå°†æ›´æ–°åçš„æƒé‡åœ¨åŒæ­¥åˆ°å„ä¸ªActorä¸Šï¼ˆApeX)ï¼›
* ä½¿ç”¨TD(N-steps)çš„æ–¹å¼è¿›è¡Œå¤„ç†ï¼Œå‡å°Biasï¼›
* å¯ä»¥ä½¿ç”¨PERæŠ€æœ¯ï¼ˆä¼˜å…ˆç»éªŒå›æ”¾ï¼‰ï¼›
* Critic Net -- C51-based method.
* é¡¹ç›®è·³è½¬é“¾æ¥ğŸ”—: [D4PG](https://github.com/HzcIrving/DLRL-PlayGround/tree/main/Distributional%20RL/D4PG/)
