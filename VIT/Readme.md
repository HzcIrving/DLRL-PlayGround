## VIT - Vision Transformer

ğŸ‘ [Paper: An image is worth 16Ã—16 words: transformers for image recognition at scale](https://arxiv.org/pdf/2010.11929.pdf)
![img_1.png](img_1.png)

### Refs

[ã€å°ç™½å­¦ä¹ ç¬”è®°ã€‘Pytorchä¹‹Vision Transformer(ViT)ï¼ŒCIFAR10å›¾åƒåˆ†ç±», Colab æºç åˆ†äº«](https://zhuanlan.zhihu.com/p/448687823)

[è°·æ­Œå¤§è„‘æå‡ºæ–°å‹æ¿€æ´»å‡½æ•°Swishæƒ¹äº‰è®®ï¼šå¯ç›´æ¥æ›¿æ¢å¹¶ä¼˜äºReLUï¼Ÿï¼ˆé™„æœºå™¨ä¹‹å¿ƒæµ‹è¯•ï¼‰](https://zhuanlan.zhihu.com/p/30332306)

[vit-pytorch](https://github.com/lucidrains/vit-pytorch)

[Vision-Transformer](https://github.com/ra1ph2/Vision-Transformer)

### Key Points

- VITæ˜¯Transformeråœ¨CVå›¾ç‰‡åˆ†ç±»ç§çš„ä¸€ç§åº”ç”¨ï¼ŒVITçš„å®éªŒç»“è®ºæ˜¯ï¼Œåœ¨é¢„è®­ç»ƒDatasetè¶³å¤Ÿå¤§çš„å‰æä¸‹ï¼Œæ‰€æœ‰æ•°æ®é›†çš„è¡¨ç°æ˜¯è¶…è¿‡ResNetçš„ã€‚
- VITçš„æœ¬è´¨å°±æ˜¯ä¸€ä¸ªTransformerçš„Encoderç½‘ç»œã€‚

![image.png](./assets/image.png)

- åœ¨åŸå§‹è®ºæ–‡ä¸­ï¼š

  - è‹¥åœ¨å¦‚æœåœ¨ImageNet(Small)ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œé‚£ViTçš„è¡¨ç°ç”šè‡³è¦æ¯”ResNetè¿˜å·®ä¸€äº›ã€‚
  - åœ¨ImageNet-21K(Medium)ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼ŒViTçš„è¡¨ç°is comparable to ResNetã€‚
  - åœ¨JFG(large)ä¸Šé¢„è®­ç»ƒï¼ŒViTæ¯”ResNetçš„å‡†ç¡®ç‡é«˜1%.
- å›¾åƒæ•°æ®é¢„å¤„ç†
  - ![img_2.png](img_2.png)
  - å‡†å¤‡æ•°æ®
  - Patches Embedding
  - åŠ å…¥ã€CLSã€‘Token.
  - Position Embedding.
- Transformer Encoder Block:
  - ![img_3.png](img_3.png)

### å®éªŒè¿‡ç¨‹

#### Test01: Cifar10 + 12Layer Transformer Encoder Block (æ²¡æœ‰åŠ è½½Pretrained Model)

- åœ¨Colabä¸­ï¼Œç›´æ¥è®­ç»ƒVITæ¨¡å‹ï¼›
- è®­ç»ƒäº†100ä¸ªepochsï¼›
- VIT from scratch;
  - ![img.png](img.png)

#### Test02: Cifar10 + 12Layer Transformer Encoder Block

- é¢„è®­ç»ƒæ¨¡å‹ "ViT-B_16"

  - [ä¸‹è½½åœ°å€ ğŸ‰ï¸](https://console.cloud.google.com/storage/browser/vit_models/imagenet21k?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false)
- å‚æ•°é…ç½®

  ```
  class VITConfig:
      log_dir = "./TB_log/"
      dataset = "cifar10" # "cifar100"
      model_type = "ViT-B_16"
      pretrained_dir = "./Pretrained/imagenet21k_ViT-B_16.npz" # é¢„è®­ç»ƒæ¨¡å‹å­˜æ”¾ä½ç½®
      save_dir = "./Model/"
      record_algo = "Pretrained_VIT_Cifar10_ViTB16_"
      test_cycles = datetime.datetime.now().strftime('%Y%m%d_%H%M')
      decay_type = "cosine" #  "cosine", "linear" å†³å®šäº†å­¦ä¹ ç‡Schedulerç±»å‹
      device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

      TB_log = True

      img_size = 224
      train_batch_size = 32 #512
      eval_batch_size = 16 #64
      eval_every = 100 # Run prediction on validation set every so many steps.
      learning_rate = 3e-2 # SGDèµ·å§‹å­¦ä¹ ç‡
      weight_decay = 0 #
      num_steps = 10000 # Total number of training epochs to perform.
      warmup_steps = 500 # å¼€å§‹çš„Warmup Stepæ•°
      max_grad_norm = 1.0

      local_rank = -1 # local_rank for distributed training on gpus
      seed = 42
      gradient_accumulation_steps = 1 # Number of updates steps to accumulate before performing a backward/update pass.
  ```
- è®­ç»ƒè¿‡ç¨‹
  ![img_4.png](img_4.png)
  ![img_5.png](img_5.png)
